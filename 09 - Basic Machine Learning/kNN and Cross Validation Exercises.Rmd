---
title: "kNN and Cross Validation Exercises"
date: "October 3, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Load the following dataset

library(GSE5859Subset)
data(GSE5859Subset)

#And define the outcome and predictors. To make the problem more difficult we will only consider autosomal genes:

y = factor(sampleInfo$group)
X = t(geneExpression)
out = which(geneAnnotation$CHR%in%c("chrX","chrY"))
X = X[,-out]

#Note, you will also need to load the following:

library(caret)
```
1. Set the seed to 1 set.seed(1) then use the createFolds function in the caret package to create 10 folds of y.
What is the 2nd entry in the fold 3?
```{r}
set.seed(1)
idx <- createFolds(y, k=10) # splits the data into k groups
sapply(idx, length) # returns number of elements of y in each fold
idx[[3]][2] # returns the 2nd entry of fold 3

sapply(idx,function(ind) table(y[ind])) # check that the folds are 0's and 1's
```

2. For the following questions we are going to use kNN. We are going to consider a smaller set of predictors by filtering genes using t-tests. Specifically, we will perform a t-test and select the m genes with the smallest p-values.

Let m = 8 and k = 5. Train kNN by leaving out the second fold idx[[2]].
How many mistakes do we make on the test set? Remember it is indispensable that you perform the ttest on the training data.
```{r}
#use example on page 403
library(class)
library(genefilter)
m <- 8
k <- 5
ind <- idx[[2]] # leave this fold out
pvals <- colttests(X[-ind,],factor(y[-ind]))$p.val # perform ttests on training data
#or pvals = rowttests(t(X[-ind,]),factor(y[-ind]))$p.val
ind2 <- order(pvals)[1:m]
pred <- knn(train = X[-ind,ind2],test=X[ind,ind2],cl=y[-ind],k=k)

table(true=y[ idx[[2]] ], pred)
sum(pred != y[ind])
```
3. Now run the code for kNN and Cross Validation Exercises #2 for all 10 folds and keep track of the errors. What is our error rate (number of errors divided by number of predictions)?
```{r}
# Use example on page 405
set.seed(1)
ks <- 1:10
result <- sapply(ks, function(k) {
  ##try out each version of k from 1 to 12
  res.k <- sapply(seq_along(idx), function(i) {
    ##loop over each of the 10 cross-validation folds
    ##predict the held-out samples using k nearest neighbors
    ind <- idx[[i]] # leave this fold out
    pvals <- colttests(X[-ind,],factor(y[-ind]))$p.val # perform ttests on training data
    ind2<-order(pvals)[1:m]
    pred <- knn(train = X[-ind,ind2],test=X[ind,ind2],cl=y[-ind],k=k)
    ##the ratio of misclassified samples
    sum(pred != y[ind])
  })
  sum(res.k) / length(y)

})
sum(result) / length(result)
```

```{r}
#Model answer
library(class)
library(genefilter)
m=8
k=5
result = sapply(idx,function(ind){
  pvals = rowttests(t(X[-ind,]),factor(y[-ind]))$p.val
  ind2 = order(pvals)[1:m]
  predict=knn(X[-ind,ind2],X[ind,ind2],y[-ind],k=k)
  sum(predict!=y[ind])
})
sum(result)/length(y)
```
4. Now we are going to select the best values of k and m. Use the expand grid function to try out the following values:
```{r}
ms=2^c(1:11)
ks=seq(1,9,2)
params = expand.grid(k=ks,m=ms)
```
Now use apply or a loop to obtain error rates for each of these pairs of parameters. Which pair of parameters minimizes the error rate?
k=?, m=?
```{r}
error_rates = apply(params,MARGIN=1,function(i){
  k =  i[1]
  m =  i[2]
  result = sapply(idx,function(ind){
    pvals <- colttests(X[-ind,],factor(y[-ind]))$p.val
    ind2 = order(pvals)[1:m]
    pred <- knn(train = X[-ind,ind2],test=X[ind,ind2],cl=y[-ind],k=k)
    sum(pred != y[ind])
  })
  sum(result) / length(y)
  })
params[which.min(error_rates),]

##make a plot and confirm its just one min:
errors = matrix(error_rates,5,11)
library(rafalib)
mypar(1,1)
matplot(ms,t(errors),type="l",log="x")
legend("topright",as.character(ks),lty=seq_along(ks),col=seq_along(ks))
```


5. Repeat question kNN and Cross Validation Exercises #4 but now perform the t-test filtering before the cross validation. Note how this biases the entire result and gives us much lower estimated error rates.
What is the minimum error rate?

```{r}
pvals <- colttests(X[-ind,],factor(y[-ind]))$p.val
error_rates = apply(params,MARGIN=1,function(i){
  k =  i[1]
  m =  i[2]
  result = sapply(idx,function(ind){
    ind2 = order(pvals)[1:m]
    pred <- knn(train = X[-ind,ind2],test=X[ind,ind2],cl=y[-ind],k=k)
    sum(pred != y[ind])
  })
  sum(result) / length(y)
  })
params[which.min(error_rates),]
error_matrix = matrix(error_rates,5,11)
min(error_matrix)




##make a plot and compare to previous question
errors = matrix(errors,5,11)
library(rafalib)
mypar(1,1)
matplot(ms,t(errors),type="l",log="x")
legend("topright",as.character(ks),lty=seq_along(ks),col=seq_along(ks))

```
6. Repeat the cross-validation we performed in question kNN and Cross Validation Exercises #4 but now instead of defining y as sampleInfo$group use:

y = factor(as.numeric(format( sampleInfo$date, "%m")=="06"))
  

What is the minimum error rate now?

```{r}
y = factor(as.numeric(format( sampleInfo$date, "%m")=="06"))
error_rates = apply(params,MARGIN=1,function(i){
  k =  i[1]
  m =  i[2]
  result = sapply(idx,function(ind){
    pvals <- colttests(X[-ind,],factor(y[-ind]))$p.val
    ind2 = order(pvals)[1:m]
    pred <- knn(train = X[-ind,ind2],test=X[ind,ind2],cl=y[-ind],k=k)
    sum(pred != y[ind])
  })
  sum(result) / length(y)
  })
params[which.min(error_rates),]
error_matrix = matrix(error_rates,5,11)
min(error_matrix)


##make a plot and confirm its just one min:
errors = matrix(error_rates,5,11)
library(rafalib)
mypar(1,1)
matplot(ms,t(errors),type="l",log="x")
legend("topright",as.character(ks),lty=seq_along(ks),col=seq_along(ks))
```





