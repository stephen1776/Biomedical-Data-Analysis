---
title: "QR Exercises"
author: "Stephen Blatti"
date: "August 26, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



We will use the spider dataset to try out the QR decomposition as a solution to linear models. Load the full spider dataset, by using the code in the Interactions and Contrasts book page. Run a linear model of the friction coefficient with two variable (no interactions):

fit <- lm(friction ~ type + leg, data=spider)

The solution we are interested in solving is:

betahat <- coef(fit)

So for our matrix work, 

Y <- matrix(spider$friction, ncol=1)

X <- model.matrix(~ type + leg, data=spider)

In the material on QR decomposition, we saw that the solution for beta is:

R beta = Q^T Y
```{r}
filename <- "spider_wolff_gorb_2013.csv"
library(downloader)
if (!file.exists(filename)) download(url, filename)
spider <- read.csv(filename, skip=1)
fit <- lm(friction ~ type + leg, data=spider)
betahat <- coef(fit)
Y <- matrix(spider$friction, ncol=1)
X <- model.matrix(~ type + leg, data=spider)
```

1. What is the first row, first column element in the Q matrix for this linear model?
```{r}
QR <- qr(X)
Q <- qr.Q( QR )
Q[1,1]
```

2. What is the first row, first column element in the R matrix for this linear model?
```{r}
R <- qr.R( QR )
R[1,1]
```

3. What is the first row, first column element of Q^T Y (use crossprod() as in the book page)
```{r}
# betahat <- backsolve(R, crossprod(Q, Y) )
# betahat[1,1]
crossprod(Q,Y)[1,1]
```



Finally convince yourself that the QR gives the least squares solution by putting all the pieces together:

R^-1 (Q^T Y) compared to betahat


Going Further

It is important to keep in mind that linear models can be extended in many directions. We have produced a page in the book which gives some description and examples of extensions to linear models, which you might come across in analyzing data in the life sciences. Some of these topics, in particular GLM and many simultaneous linear models will be covered in the other courses of the series.

    Robust linear models
    Generalized linear models (GLM)
    Mixed effects linear models
    Bayesian linear models
    Penalized linear models
    Many simultaneous linear models










