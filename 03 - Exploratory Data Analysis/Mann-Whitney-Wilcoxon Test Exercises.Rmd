---
title: "Mann-Whitney-Wilcoxon Test Exercises"
author: "Stephen Blatti"
date: "August 12, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

        We are going to explore the properties of robust statistics. We will use one of the datasets included in R, which contains weight of chicks in grams as they grow from day 0 to day 21. This dataset also splits up the chicks by different protein diets, which are coded from 1 to 4. We use this dataset to also show an important operation in R (not related to robust summaries): reshape.
        
        This dataset is built into R and can be loaded with:
        
        data(ChickWeight)
        
        To begin, take a look at the weights of all observations over time and color the points to represent the Diet:
        
        head(ChickWeight)
        plot( ChickWeight$Time, ChickWeight$weight, col=ChickWeight$Diet)
        
        First, notice that the rows here represent time points rather than individuals. To facilitate the comparison of weights at different time points and across the different chicks, we will reshape the data so that each row is a chick. In R we can do this with the reshape function:
        
        chick = reshape(ChickWeight, idvar=c("Chick","Diet"), timevar="Time",
                        direction="wide")
        
        The meaning of this line is: reshape the data from _long_ to _wide_, where the columns Chick and Diet are the ID's and the column Time indicates different observations for each ID. Now examine the head of this dataset:
        
        head(chick)
        
        We also want to remove any chicks that have missing observations at any time points (NA for "not available"). The following line of code identifies these rows and then removes them:
        
        chick = na.omit(chick)

```{r}
data(ChickWeight)
head(ChickWeight)
plot( ChickWeight$Time, ChickWeight$weight, col=ChickWeight$Diet)
chick = reshape(ChickWeight, idvar=c("Chick","Diet"), timevar="Time",
                        direction="wide")
head(chick)
chick = na.omit(chick)
```

1. Save the weights of the chicks on day 4 from diet 1 as a vector x. Save the weights of the chicks on day 4 from diet 4 as a vector y. Perform a t-test comparing x and y (in R the function t.test(x,y) will perform the test). Then perform a Wilcoxon test of x and y (in R the function wilcox.test(x,y) will perform the test). A warning will appear that an exact p-value cannot be calculated with ties, so an approximation is used, which is fine for our purposes.

Perform a t-test of x and y, after adding a single chick of weight 200 grams to x (the diet 1 chicks). What is the p-value from this test? The p-value of a test is available with the following code: t.test(x,y)$p.value 

```{r}
library(dplyr)
x <- filter(chick, Diet =="1") %>%
  select(weight.4) %>%
  unlist

y <- filter(chick, Diet =="4") %>%
  select(weight.4) %>%
  unlist
t.test(x,y)
x_outL <- c(x, 200)
t.test(x_outL,y)$p.value

# or
# x = chick$weight.4[chick$Diet == 1]
# y = chick$weight.4[chick$Diet == 4]
# t.test(c(x, 200), y)$p.value
```
2. Do the same for the Wilcoxon test. The Wilcoxon test is robust to the outlier. In addition, it has less assumptions that the t-test on the distribution of the underlying data. 
```{r}
wilcox.test(x_outL,y)

# x = chick$weight.4[chick$Diet == 1]
# y = chick$weight.4[chick$Diet == 4]
# wilcox.test(c(x, 200), y, exact=FALSE)$p.value
```
3. We will now investigate a possible downside to the Wilcoxon-Mann-Whitney test statistic. Using the following code to make three boxplots, showing the true Diet 1 vs 4 weights, and then two altered versions: one with an additional difference of 10 grams and one with an additional difference of 100 grams. Use the x and y as defined above, NOT the ones with the added outlier.

    library(rafalib)
    mypar(1,3)
    boxplot(x,y)
    boxplot(x,y+10)
    boxplot(x,y+100)

What is the difference in t-test statistic (obtained by t.test(x,y)$statistic) between adding 10 and adding 100 to all the values in the group 'y'? Take the the t-test statistic with x and y+10 and subtract the t-test statistic with x and y+100. The value should be positive.

```{r}
library(rafalib)
par(mfrow=c(1,3))
boxplot(x,y)
boxplot(x,y+10)
boxplot(x,y+100)
```

```{r}
t.test(x,y+10)$statistic - t.test(x,y+100)$statistic
```
4. Examine the Wilcoxon test statistic for x and y+10 and for x and y+100. Because the Wilcoxon works on ranks, once the two groups show complete separation, that is all points from group 'y' are above all points from group 'x', the statistic will not change, regardless of how large the difference grows. Likewise, the p-value has a minimum value, regardless of how far apart the groups are. This means that the Wilcoxon test can be considered less powerful than the t-test in certain contexts. In fact, for small sample sizes, the p-value can't be very small, even when the difference is very large. What is the p-value if we compare c(1,2,3) to c(4,5,6) using a Wilcoxon test? 

```{r}
wilcox.test(c(1,2,3), c(4,5,6))$p.value
```

5. What is the p-value if we compare c(1,2,3) to c(400,500,600) using a Wilcoxon test? 
```{r}
wilcox.test(c(1,2,3), c(400,500,600))$p.value
```


























